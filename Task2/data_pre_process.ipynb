{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 加载数据\n",
    "data = pd.read_csv(\"F:/MLdata/project1_data.csv\")\n",
    "\n",
    "# 将日期字符串转换为日期类型，并提取年份\n",
    "data['year'] = pd.to_datetime(data['date'], format='%Y%m%d').dt.year\n",
    "\n",
    "# 按股票代码分组\n",
    "grouped_data = data.groupby('code')\n",
    "\n",
    "sequence_length = 64  # 序列长度\n",
    "features = ['open', 'high', 'low', 'close', 'volume']  # 特征列\n",
    "\n",
    "# 初始化列表\n",
    "X_train_list = []\n",
    "y_train_list = []\n",
    "X_test_list = []\n",
    "y_test_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm(total=len(grouped_data))\n",
    "for code, group_df in grouped_data:\n",
    "    scaler = MinMaxScaler()\n",
    "    group_df[features] = scaler.fit_transform(group_df[features])\n",
    "\n",
    "    if len(group_df) < sequence_length:\n",
    "        # 如果分组长度不够，跳过该分组\n",
    "        progress_bar.update(1)\n",
    "        print(\"jump\", code)\n",
    "        continue\n",
    "\n",
    "    # 按年份分割数据\n",
    "    train_df = group_df[group_df['year'].isin([2010, 2011, 2012])]\n",
    "    test_df = group_df[group_df['year'] == 2013]\n",
    "\n",
    "    def generate_sequences(df, X_list, y_list):\n",
    "        if len(df) >= sequence_length:\n",
    "            X = []\n",
    "            for i in range(len(df) - sequence_length):\n",
    "                sequence_data = df[features].values[i:i+sequence_length]\n",
    "                # Check the dimensionality of sequence_data\n",
    "                if np.ndim(sequence_data) == 2:  # Ensure it's a 3D array\n",
    "                    X.append(sequence_data)\n",
    "            if X:  # Ensure X is not empty before appending\n",
    "                X = np.array(X)\n",
    "                y = df['label'].values[sequence_length:]\n",
    "                X_list.append(X)\n",
    "                y_list.append(y)\n",
    "\n",
    "\n",
    "    # 对训练集和测试集数据分别生成序列\n",
    "    generate_sequences(train_df, X_train_list, y_train_list)\n",
    "    generate_sequences(test_df, X_test_list, y_test_list)\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "# 组合训练集和测试集的数据\n",
    "X_train = np.vstack(X_train_list)\n",
    "y_train = np.concatenate(y_train_list)\n",
    "X_test = np.vstack(X_test_list)\n",
    "y_test = np.concatenate(y_test_list)\n",
    "\n",
    "print(\"Train X shape:\", X_train.shape)\n",
    "print(\"Train y shape:\", y_train.shape)\n",
    "print(\"Test X shape:\", X_test.shape)\n",
    "print(\"Test y shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 将变量保存到文件\n",
    "with open(\"F:/MLdata/data.pkl\", 'wb') as f:\n",
    "    pickle.dump((X_train, X_test, y_train, y_test), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 从文件中加载变量\n",
    "with open(\"F:/MLdata/data.pkl\", 'rb') as f:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
